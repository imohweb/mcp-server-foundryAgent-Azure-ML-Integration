# Presentation Quick Reference

## üé§ Tech Talk: MCP Foundry ML Integration
**Azure NG Community - November 2025**

---

## üéØ The Problem We're Solving

**Challenge**: How can AI agents safely interact with enterprise ML systems?

‚ùå **What Doesn't Work:**
- Direct API calls from LLMs (security risk)
- Hardcoded integrations (not scalable)
- Custom protocols for each system (maintenance nightmare)

‚úÖ **Our Solution:**
- Standardized Model Context Protocol (MCP)
- Secure middleware layer
- Validated tool boundaries
- Enterprise-grade governance

---

## üèóÔ∏è Architecture Overview (Show Diagram)

**3 Layers:**

1. **Layer 1: Intelligence** (Microsoft Foundry Agent)
   - Natural language understanding
   - Intent recognition
   - Tool selection

2. **Layer 2: Integration** (MCP Server)
   - Secure gateway
   - Tool validation
   - Request routing

3. **Layer 3: Execution** (Azure ML)
   - Real ML operations
   - Pipeline execution
   - Resource management

---

## üí° Key Talking Points

### 1. Why MCP?
- **Standardization**: One protocol for all tools
- **Security**: Validated, approved tool calls
- **Flexibility**: Easy to add new tools
- **Governance**: Audit trails and control

### 2. Why This Architecture?
- **Separation of Concerns**: Each layer has one job
- **Scalability**: Can scale layers independently
- **Maintainability**: Changes isolated to specific layers
- **Testability**: Can test each layer separately

### 3. Real-World Impact
- Automate ML workflows with natural language
- Reduce time from idea to execution
- Enable non-technical users to trigger ML operations
- Maintain enterprise security and compliance

---

## üé¨ Live Demo Script

### Demo 1: Verify Server is Running
```bash
# Show in browser
http://localhost:8000/

# Show available tools
http://localhost:8000/tools

# Show interactive docs
http://localhost:8000/docs
```

**Say:** "The MCP server is running and exposing 5 tools - 2 demo tools and 3 production Azure ML tools."

---

### Demo 2: Test Simple Tool (greet)
```bash
curl -X POST http://localhost:8000/mcp/call \
  -H "Content-Type: application/json" \
  -d '{"tool_name": "greet", "parameters": {"name": "Azure NG Community"}}'
```

**Expected Response:**
```json
{
  "status": "success",
  "result": "Hello, Azure NG Community! Welcome to the MCP Foundry ML integration."
}
```

**Say:** "This demonstrates the basic MCP tool calling pattern - send a tool name and parameters, get a response."

---

### Demo 3: Test Calculation Tool (add_numbers)
```bash
curl -X POST http://localhost:8000/mcp/call \
  -H "Content-Type: application/json" \
  -d '{"tool_name": "add_numbers", "parameters": {"a": 42, "b": 58}}'
```

**Expected Response:**
```json
{
  "status": "success",
  "result": {
    "sum": 100,
    "inputs": {"a": 42, "b": 42},
    "operation": "42 + 58 = 100"
  }
}
```

**Say:** "This shows how parameters are passed and structured responses are returned."

---

### Demo 4: Show Code Walkthrough

**File: `src/mcp_server/main.py`**
- Point out the FastAPI setup
- Show the `/mcp/call` endpoint
- Explain the routing logic

**File: `src/mcp_server/tools/azure_ml_tools.py`**
- Show `run_aml_pipeline()` function
- Explain error handling
- Point out the bridge pattern

**File: `src/foundry_agent/bridge.py`**
- Show `McpAzureMlBridge` class
- Explain Azure ML integration
- Highlight authentication approach

**Say:** "The code is clean, modular, and follows Python best practices."

---

### Demo 5: Architecture Flow (Optional - Time Permitting)

**Trace a Request:**
```
1. User: "Run my ML pipeline with batch size 100"
   ‚Üì
2. Foundry Agent processes natural language
   ‚Üì
3. Agent calls MCP Server: POST /mcp/call
   {
     "tool_name": "run_aml_pipeline",
     "parameters": {
       "payload": {"batch_size": 100},
       "experiment_name": "demo"
     }
   }
   ‚Üì
4. MCP Server validates and routes to Azure ML tools
   ‚Üì
5. Bridge connects to Azure ML
   ‚Üì
6. Pipeline job is submitted
   ‚Üì
7. Response flows back: Job ID, Status, Details
```

---

## üîë Key Code Snippets to Show

### Snippet 1: MCP Server Endpoint
```python
@app.post("/mcp/call")
async def call_tool(request: ToolRequest):
    """Execute a tool"""
    tool_name = request.tool_name
    params = request.parameters
    
    if tool_name == "run_aml_pipeline":
        result = run_aml_pipeline(**params)
    # ... other tools
    
    return {"status": "success", "result": result}
```

### Snippet 2: Azure ML Integration
```python
def run_aml_pipeline(pipeline_job_yaml, payload, experiment_name):
    """Trigger an Azure ML pipeline"""
    bridge = McpAzureMlBridge.from_env()
    job_info = bridge.run_pipeline_direct(
        pipeline_job_yaml, payload, experiment_name
    )
    return {"status": "submitted", "job": job_info}
```

### Snippet 3: Authentication
```python
credential = DefaultAzureCredential()
ml_client = MLClient(
    credential=credential,
    subscription_id=os.environ["AZURE_SUBSCRIPTION_ID"],
    resource_group_name=os.environ["AZURE_RESOURCE_GROUP"],
    workspace_name=os.environ["AZURE_ML_WORKSPACE"]
)
```

---

## üìä Stats to Mention

- **5 Tools Exposed**: 2 demo + 3 production Azure ML tools
- **3 Architecture Layers**: Intelligence, Integration, Execution
- **Zero Direct LLM-to-Azure Calls**: All through secure MCP layer
- **100% Python**: Easy for data scientists to extend
- **FastAPI**: Modern, fast, auto-documented REST API

---

## üéì Learning Outcomes for Audience

By the end of this talk, attendees will understand:

1. ‚úÖ What MCP is and why it matters
2. ‚úÖ How to architect AI agent systems securely
3. ‚úÖ How to integrate Foundry Agents with Azure ML
4. ‚úÖ How to expose enterprise systems as MCP tools
5. ‚úÖ Best practices for production AI automation

---

## ‚ùì Q&A - Anticipated Questions

### Q: "Can this work with other cloud providers?"
**A:** Yes! The pattern is cloud-agnostic. Just swap the Azure ML bridge with AWS SageMaker or GCP Vertex AI equivalents.

### Q: "What about authentication and security?"
**A:** We use Azure's DefaultAzureCredential which supports CLI, managed identity, and service principals. For production, add OAuth2/JWT to the FastAPI endpoints.

### Q: "How do you handle long-running pipelines?"
**A:** The MCP server immediately returns a job ID. The agent can then poll using `get_aml_job_status()`. For real-time updates, implement webhooks or Azure Event Grid.

### Q: "What's the latency?"
**A:** MCP call overhead is <100ms. Pipeline submission to Azure ML is ~1-2 seconds. The actual ML job time depends on the workload.

### Q: "Can multiple agents call the same MCP server?"
**A:** Absolutely! The FastAPI server is stateless and can handle concurrent requests. Scale horizontally as needed.

### Q: "Where's the code?"
**A:** GitHub link: [Available in session chat/materials]

---

## üöÄ Next Steps for Attendees

**After This Talk, You Can:**

1. Clone the repo
2. Follow the setup guide in README.md
3. Read the detailed implementation guide
4. Customize tools for your use case
5. Deploy to production (see deployment section)

**Resources:**
- Implementation Guide: `docs/IMPLEMENTATION_GUIDE.md`
- README: Full setup instructions
- Code: Fully commented and documented

---

## üìû Contact & Follow-Up

**GitHub Repo**: [Your repo link]
**LinkedIn**: [Your LinkedIn]
**Email**: [Your email]
**Azure NG Community**: [Community link]

**Call to Action:**
- ‚≠ê Star the repo
- üç¥ Fork and customize
- üí¨ Share your implementations
- ü§ù Contribute improvements

---

## üé¨ Closing Statement

"Today we've shown how to safely bridge the gap between AI agents and enterprise ML systems using MCP. This isn't just a demo - it's a production-ready pattern you can use in your organizations today. The code is open source, the architecture is proven, and the benefits are clear: faster ML workflows, better security, and AI that actually works with your enterprise systems. Thank you!"

---

**Presentation Time Allocation:**
- Introduction & Problem (3 min)
- Architecture Overview (5 min)
- Live Demos (7 min)
- Code Walkthrough (5 min)
- Q&A (10 min)

**Total: 30 minutes**

---

**Good luck with your presentation! üéâ**
